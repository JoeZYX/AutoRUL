{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook models are trained on CMAPS (using the automated pipeline) and the results are compared with the results from original code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from utilities import *\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import os\n",
    "from datetime import datetime\n",
    "import rul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 1000)\n",
    "pd.set_option('display.max_rows',300)\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPARATION\n",
    "## Load the training data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_name = ['engine_id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3',\n",
    "               's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14',\n",
    "               's15', 's16', 's17', 's18', 's19', 's20', 's21']\n",
    "\n",
    "Data_id = \"FD002\"\n",
    "\n",
    "train_FD = pd.read_table(\"./CMAPSSData/train_{}.txt\".format(Data_id), header=None, delim_whitespace=True)\n",
    "train_FD.columns = column_name\n",
    "\n",
    "\n",
    "test_FD = pd.read_table(\"./CMAPSSData/test_{}.txt\".format(Data_id), header=None, delim_whitespace=True)\n",
    "test_FD.columns = column_name\n",
    "\n",
    "RUL_FD = pd.read_table(\"./CMAPSSData/RUL_{}.txt\".format(Data_id), header=None, delim_whitespace=True) # RUL for test data, for each entile engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_FD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_FD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUL_FD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUL with pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'rul' from 'c:\\\\Users\\\\I539001\\\\OneDrive - SAP SE\\\\PA2\\\\AL\\\\AutoRUL\\\\rul.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import rul\n",
    "importlib.reload(rul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = rul.RemainingUsefulLife(train_FD, test_FD, test_rul_per_rtf_id = RUL_FD, max_life=120,  epochs = 30, data_id = Data_id, rtf_id = \"engine_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Configuration!\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " module_wrapper (ModuleWrapp  (None, 5, 12, 1, 10)     5900      \n",
      " er)                                                             \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 5, 12, 1, 10)     40        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " module_wrapper_1 (ModuleWra  (None, 8, 1, 20)         18160     \n",
      " pper)                                                           \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 8, 1, 20)         80        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 160)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 150)               24150     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 151       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,481\n",
      "Trainable params: 48,421\n",
      "Non-trainable params: 60\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "3011/3011 [==============================] - 142s 37ms/step - loss: 618.6033 - val_loss: 416.1781 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "3011/3011 [==============================] - 105s 35ms/step - loss: 455.8385 - val_loss: 416.9199 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "3011/3011 [==============================] - 97s 32ms/step - loss: 426.9435 - val_loss: 537.3710 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "3011/3011 [==============================] - 84s 28ms/step - loss: 412.1312 - val_loss: 420.8767 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "3011/3011 [==============================] - 96s 32ms/step - loss: 390.6240 - val_loss: 469.4868 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "3011/3011 [==============================] - ETA: 0s - loss: 375.2966\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "3011/3011 [==============================] - 98s 33ms/step - loss: 375.2966 - val_loss: 441.8162 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "3011/3011 [==============================] - 77s 26ms/step - loss: 332.1529 - val_loss: 351.2763 - lr: 3.0000e-04\n",
      "Epoch 8/30\n",
      "3011/3011 [==============================] - 81s 27ms/step - loss: 318.3874 - val_loss: 330.9466 - lr: 3.0000e-04\n",
      "Epoch 9/30\n",
      "3011/3011 [==============================] - 84s 28ms/step - loss: 314.6563 - val_loss: 339.1415 - lr: 3.0000e-04\n",
      "Epoch 10/30\n",
      "3011/3011 [==============================] - 121s 40ms/step - loss: 311.5790 - val_loss: 363.7929 - lr: 3.0000e-04\n",
      "Epoch 11/30\n",
      "3011/3011 [==============================] - 131s 43ms/step - loss: 307.3803 - val_loss: 364.0767 - lr: 3.0000e-04\n",
      "Epoch 12/30\n",
      "3011/3011 [==============================] - 105s 35ms/step - loss: 303.3761 - val_loss: 325.2560 - lr: 3.0000e-04\n",
      "Epoch 13/30\n",
      "3011/3011 [==============================] - 123s 41ms/step - loss: 304.0280 - val_loss: 332.3783 - lr: 3.0000e-04\n",
      "Epoch 14/30\n",
      "3011/3011 [==============================] - 130s 43ms/step - loss: 300.3620 - val_loss: 347.8262 - lr: 3.0000e-04\n",
      "Epoch 15/30\n",
      "3011/3011 [==============================] - 117s 39ms/step - loss: 299.6044 - val_loss: 323.1426 - lr: 3.0000e-04\n",
      "Epoch 16/30\n",
      "3011/3011 [==============================] - 116s 39ms/step - loss: 297.3589 - val_loss: 310.5902 - lr: 3.0000e-04\n",
      "Epoch 17/30\n",
      "3011/3011 [==============================] - 123s 41ms/step - loss: 295.8766 - val_loss: 361.5059 - lr: 3.0000e-04\n",
      "Epoch 18/30\n",
      "3011/3011 [==============================] - 112s 37ms/step - loss: 292.5904 - val_loss: 334.8304 - lr: 3.0000e-04\n",
      "Epoch 19/30\n",
      "3011/3011 [==============================] - 118s 39ms/step - loss: 291.0668 - val_loss: 337.0914 - lr: 3.0000e-04\n",
      "Epoch 20/30\n",
      "3011/3011 [==============================] - 119s 40ms/step - loss: 289.3021 - val_loss: 361.5406 - lr: 3.0000e-04\n",
      "Epoch 21/30\n",
      "3010/3011 [============================>.] - ETA: 0s - loss: 289.7713\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "3011/3011 [==============================] - 119s 40ms/step - loss: 289.7380 - val_loss: 345.9661 - lr: 3.0000e-04\n",
      "Epoch 22/30\n",
      "3011/3011 [==============================] - 102s 34ms/step - loss: 271.4500 - val_loss: 359.2897 - lr: 9.0000e-05\n",
      "Epoch 23/30\n",
      "3011/3011 [==============================] - 86s 29ms/step - loss: 268.9792 - val_loss: 305.9088 - lr: 9.0000e-05\n",
      "Epoch 24/30\n",
      "3011/3011 [==============================] - 82s 27ms/step - loss: 267.8590 - val_loss: 323.3586 - lr: 9.0000e-05\n",
      "Epoch 25/30\n",
      "3011/3011 [==============================] - 84s 28ms/step - loss: 267.5898 - val_loss: 309.2472 - lr: 9.0000e-05\n",
      "Epoch 26/30\n",
      "3011/3011 [==============================] - 84s 28ms/step - loss: 266.7629 - val_loss: 315.8254 - lr: 9.0000e-05\n",
      "Epoch 27/30\n",
      "3011/3011 [==============================] - 77s 26ms/step - loss: 265.6518 - val_loss: 334.9736 - lr: 9.0000e-05\n",
      "Epoch 28/30\n",
      "3011/3011 [==============================] - ETA: 0s - loss: 264.5911\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "3011/3011 [==============================] - 73s 24ms/step - loss: 264.5911 - val_loss: 312.1845 - lr: 9.0000e-05\n",
      "Epoch 29/30\n",
      "3011/3011 [==============================] - 75s 25ms/step - loss: 259.3592 - val_loss: 329.6243 - lr: 2.7000e-05\n",
      "Epoch 30/30\n",
      "3011/3011 [==============================] - 74s 25ms/step - loss: 258.3043 - val_loss: 317.7411 - lr: 2.7000e-05\n",
      "1526/1526 [==============================] - 9s 5ms/step\n",
      "The RMSE on Training dataset FD002 is 16.22504997253418.\n",
      "9/9 [==============================] - 0s 5ms/step\n",
      "The RMSE on test dataset FD002 is 29.73402214050293.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(     y_batch_test  y_batch_pred_test\n",
       " 0        18.00000           14.51170\n",
       " 1        79.00000          101.60510\n",
       " 2       106.00000          117.95893\n",
       " 3       110.00000           67.06764\n",
       " 4        15.00000           23.05436\n",
       " 5       155.00000          113.74578\n",
       " 6         6.00000            5.51960\n",
       " 7        90.00000           61.54238\n",
       " 8        11.00000           25.91580\n",
       " 9        79.00000          107.44836\n",
       " 10        6.00000           11.49705\n",
       " 11       73.00000          113.87051\n",
       " 12       30.00000           45.24179\n",
       " 13       11.00000           14.70026\n",
       " 14       37.00000           57.57924\n",
       " 15       67.00000          101.49213\n",
       " 16       68.00000           72.78854\n",
       " 17       99.00000          110.62924\n",
       " 18       22.00000           27.19168\n",
       " 19       54.00000           88.70197\n",
       " 20       97.00000           84.41655\n",
       " 21       10.00000           12.29503\n",
       " 22      142.00000          100.86407\n",
       " 23       77.00000           76.44191\n",
       " 24       88.00000           85.17959\n",
       " 25      163.00000          115.00362\n",
       " 26      126.00000          116.89668\n",
       " 27      138.00000          115.08305\n",
       " 28       83.00000          105.98936\n",
       " 29       78.00000           56.59169\n",
       " 30       75.00000          108.01314\n",
       " 31       11.00000           21.25875\n",
       " 32       53.00000           54.94007\n",
       " 33      173.00000          118.44095\n",
       " 34       63.00000           72.76446\n",
       " 35      100.00000           85.93963\n",
       " 36      151.00000          100.57102\n",
       " 37       55.00000           74.76772\n",
       " 38       48.00000           40.98057\n",
       " 39       37.00000           35.82526\n",
       " 40       44.00000           41.48877\n",
       " 41       27.00000           28.24451\n",
       " 42       18.00000           23.61566\n",
       " 43        6.00000           10.13264\n",
       " 44       15.00000           18.62009\n",
       " 45      112.00000          116.82491\n",
       " 46      131.00000          104.96990\n",
       " 47       13.00000           19.25377\n",
       " 48      122.00000          101.41941\n",
       " 49       13.00000           16.07825\n",
       " 50       98.00000          119.71594\n",
       " 51       53.00000           45.39293\n",
       " 52       52.00000           54.43098\n",
       " 53      106.00000           96.32609\n",
       " 54      103.00000          105.52391\n",
       " 55      152.00000          117.71804\n",
       " 56      123.00000          115.38826\n",
       " 57       26.00000           12.22486\n",
       " 58      178.00000          111.48790\n",
       " 59       73.00000           98.06337\n",
       " 60      169.00000           90.77483\n",
       " 61       39.00000           39.03092\n",
       " 62       39.00000           59.87516\n",
       " 63       14.00000           12.35836\n",
       " 64       11.00000            8.07428\n",
       " 65      121.00000          110.22816\n",
       " 66       86.00000           96.54478\n",
       " 67       56.00000           40.24143\n",
       " 68      115.00000          112.57430\n",
       " 69       17.00000           14.77749\n",
       " 70      148.00000          117.54637\n",
       " 71      104.00000           90.56281\n",
       " 72       78.00000           85.46244\n",
       " 73       86.00000          111.98267\n",
       " 74       98.00000           94.28215\n",
       " 75       36.00000           47.24922\n",
       " 76       94.00000          107.31181\n",
       " 77       52.00000           66.74596\n",
       " 78       91.00000          116.21259\n",
       " 79       15.00000            7.80086\n",
       " 80      141.00000          114.19547\n",
       " 81       74.00000           95.98516\n",
       " 82      146.00000          106.50395\n",
       " 83       17.00000           19.93607\n",
       " 84       47.00000           52.05636\n",
       " 85      194.00000          104.15144\n",
       " 86       21.00000           22.09189\n",
       " 87       79.00000           74.59148\n",
       " 88       97.00000          106.35743\n",
       " 89        8.00000           15.12050\n",
       " 90        9.00000            6.86538\n",
       " 91       73.00000           96.62251\n",
       " 92      183.00000          112.91773\n",
       " 93       97.00000           92.38966\n",
       " 94       73.00000           69.01660\n",
       " 95       49.00000           42.11945\n",
       " 96       31.00000           26.37038\n",
       " 97       97.00000           86.68625\n",
       " 98        9.00000           16.49680\n",
       " 99       14.00000           22.40181\n",
       " 100     106.00000          114.86317\n",
       " 101       8.00000            8.35885\n",
       " 102       8.00000            7.89221\n",
       " 103     106.00000           95.12983\n",
       " 104     116.00000          116.24127\n",
       " 105     120.00000          103.19705\n",
       " 106      61.00000           64.57978\n",
       " 107     168.00000          110.70512\n",
       " 108      35.00000           54.23932\n",
       " 109      80.00000           76.41304\n",
       " 110       9.00000           22.30899\n",
       " 111      50.00000           93.47772\n",
       " 112     151.00000          117.88961\n",
       " 113      78.00000           76.24138\n",
       " 114      91.00000           35.07471\n",
       " 115       7.00000            4.87235\n",
       " 116     181.00000           92.54771\n",
       " 117     150.00000           97.23318\n",
       " 118     106.00000          105.86964\n",
       " 119      15.00000           20.53292\n",
       " 120      67.00000           87.74604\n",
       " 121     145.00000          117.82932\n",
       " 122     180.00000          105.47424\n",
       " 123       7.00000           16.69927\n",
       " 124     179.00000          104.97993\n",
       " 125     124.00000          107.71086\n",
       " 126      82.00000           50.69466\n",
       " 127     108.00000          106.17003\n",
       " 128      79.00000           72.52828\n",
       " 129     121.00000          117.58553\n",
       " 130     120.00000          115.97185\n",
       " 131      39.00000           46.06243\n",
       " 132      38.00000           61.51154\n",
       " 133       9.00000           13.45375\n",
       " 134     167.00000          116.10777\n",
       " 135      87.00000           97.02654\n",
       " 136      88.00000           59.91603\n",
       " 137       7.00000            3.54076\n",
       " 138      51.00000           71.46583\n",
       " 139      55.00000           49.46209\n",
       " 140     155.00000          109.90802\n",
       " 141      47.00000           35.40955\n",
       " 142      81.00000           72.46981\n",
       " 143      43.00000           42.74010\n",
       " 144      98.00000          108.47936\n",
       " 145      10.00000           10.58384\n",
       " 146      92.00000          109.38942\n",
       " 147      11.00000           15.68198\n",
       " 148     165.00000          104.18858\n",
       " 149      34.00000           30.83300\n",
       " 150     115.00000          104.43705\n",
       " 151      59.00000           89.30650\n",
       " 152      99.00000           98.50269\n",
       " 153     103.00000          104.40593\n",
       " 154     108.00000          113.20733\n",
       " 155      83.00000          113.50562\n",
       " 156     171.00000          115.37488\n",
       " 157      15.00000           22.80273\n",
       " 158       9.00000            9.24867\n",
       " 159      42.00000           44.63683\n",
       " 160      13.00000           20.91045\n",
       " 161      41.00000           66.32209\n",
       " 162      88.00000           55.47434\n",
       " 163      14.00000           16.29089\n",
       " 164     155.00000          117.07799\n",
       " 165     188.00000          102.87408\n",
       " 166      96.00000          104.88277\n",
       " 167      82.00000          104.57251\n",
       " 168     135.00000          105.73324\n",
       " 169     182.00000           97.75481\n",
       " 170      36.00000           25.78301\n",
       " 171     107.00000          102.08076\n",
       " 172      14.00000           11.40824\n",
       " 173      95.00000           91.31285\n",
       " 174     142.00000          115.78181\n",
       " 175      23.00000           32.08158\n",
       " 176       6.00000            9.48404\n",
       " 177     144.00000          101.66357\n",
       " 178      35.00000           45.50833\n",
       " 179      97.00000           90.47379\n",
       " 180      68.00000           53.03276\n",
       " 181      14.00000            9.11775\n",
       " 182      67.00000           71.32545\n",
       " 183     191.00000          116.25755\n",
       " 184      19.00000           13.98066\n",
       " 185      10.00000            5.41638\n",
       " 186     158.00000          111.25607\n",
       " 187     183.00000          102.73455\n",
       " 188      43.00000           54.39362\n",
       " 189      12.00000           15.45876\n",
       " 190     148.00000           99.09793\n",
       " 191      13.00000           20.79696\n",
       " 192      37.00000           39.02837\n",
       " 193     122.00000          116.21175\n",
       " 194      80.00000           61.09074\n",
       " 195      93.00000          110.47043\n",
       " 196     132.00000          118.65060\n",
       " 197      32.00000           67.82109\n",
       " 198     103.00000          113.82925\n",
       " 199     174.00000           89.42003\n",
       " 200     111.00000          108.35597\n",
       " 201      68.00000          109.14448\n",
       " 202     192.00000          117.50325\n",
       " 203     121.00000          112.96141\n",
       " 204     134.00000          109.66307\n",
       " 205      48.00000           54.10037\n",
       " 206      85.00000           77.11668\n",
       " 207       8.00000           13.27188\n",
       " 208      23.00000            2.19707\n",
       " 209       8.00000            6.55531\n",
       " 210       6.00000            6.31979\n",
       " 211      57.00000           52.82341\n",
       " 212      83.00000           72.36275\n",
       " 213     172.00000          107.78094\n",
       " 214     101.00000           90.94563\n",
       " 215      81.00000          103.41940\n",
       " 216      86.00000          115.46008\n",
       " 217     165.00000          117.60788\n",
       " 218      73.00000           85.83630\n",
       " 219     121.00000          109.22792\n",
       " 220     139.00000          101.38125\n",
       " 221      75.00000           42.18865\n",
       " 222     151.00000          119.07821\n",
       " 223     145.00000          117.36409\n",
       " 224      11.00000            9.31819\n",
       " 225     108.00000           98.21426\n",
       " 226      14.00000            9.62797\n",
       " 227     126.00000           69.55209\n",
       " 228      61.00000           96.98194\n",
       " 229      85.00000          115.22285\n",
       " 230       8.00000           15.12367\n",
       " 231     101.00000           91.62830\n",
       " 232     153.00000          112.11389\n",
       " 233      89.00000          107.27589\n",
       " 234     190.00000           91.56784\n",
       " 235      12.00000           12.06451\n",
       " 236      62.00000           48.83229\n",
       " 237     134.00000          118.25159\n",
       " 238     101.00000           98.09761\n",
       " 239     121.00000          106.73601\n",
       " 240     167.00000          118.65648\n",
       " 241      17.00000           15.58250\n",
       " 242     161.00000          100.78141\n",
       " 243     181.00000          108.92222\n",
       " 244      16.00000           14.03603\n",
       " 245     152.00000          104.59641\n",
       " 246     148.00000          118.12991\n",
       " 247      56.00000           66.59675\n",
       " 248     111.00000          110.68483\n",
       " 249      23.00000            7.23642\n",
       " 250      84.00000          117.19301\n",
       " 251      12.00000            5.47999\n",
       " 252      43.00000           54.91973\n",
       " 253      48.00000           53.96497\n",
       " 254     122.00000          111.50653\n",
       " 255     191.00000           77.83289\n",
       " 256      56.00000           56.73886\n",
       " 257     131.00000          116.30458\n",
       " 258      51.00000           96.22887,\n",
       "        y_batch_train  y_batch_train\n",
       " 0          120.00000      116.86873\n",
       " 1          120.00000      112.72569\n",
       " 2          120.00000      111.95963\n",
       " 3          120.00000      118.26200\n",
       " 4          120.00000      122.05830\n",
       " ...              ...            ...\n",
       " 48814        4.00000       -2.02638\n",
       " 48815        3.00000       -3.78459\n",
       " 48816        2.00000       -4.06491\n",
       " 48817        1.00000       -4.92796\n",
       " 48818        0.00000       -3.80824\n",
       " \n",
       " [48819 rows x 2 columns])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.auto_rul()"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice: for engine_id = 6: RUL value for the last cycle of enine_id = 6 is 155. however, \n",
    "\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure shows the average RMSE\n",
    "\n",
    "| Datasets               | FD001  | FD002  | FD003 | FD004  |\n",
    "|------------------------------|--------|--------|-------|--------|\n",
    "|   LSTM (2017)           | 16.14  | 24.49  | 16.18 | 28.17  | \n",
    "|   DCNN (2018)           | 12.61  | 22.36  | 12.64 | 23.31  |\n",
    "|   DAG (2019)            | 11.96  | 20.34  | 12.46 | 22.43  | \n",
    "|   ECLSTM    | **14.92**  | **18.11**  | **13.85**  | **20.11** | \n",
    "|   Optimized Model        | 11.03 | 15.95  | 11.23  | 16.21  | \n",
    "|   Reproduced Results ECLSTM       | **14.64** | **16.39**  | **13.48**  | **19.98**  | \n",
    "|   Reproduced Results automated ECLSTM        | **to be trained** | **15.37**  | **to be trained**  | **to be trained**  | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing AutoRUL with same amount of data like in Kaggel Prod Plant dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engine_id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s12</th>\n",
       "      <th>s13</th>\n",
       "      <th>s14</th>\n",
       "      <th>s15</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.99830</td>\n",
       "      <td>0.84000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>449.44000</td>\n",
       "      <td>555.32000</td>\n",
       "      <td>1358.61000</td>\n",
       "      <td>1137.23000</td>\n",
       "      <td>5.48000</td>\n",
       "      <td>...</td>\n",
       "      <td>183.06000</td>\n",
       "      <td>2387.72000</td>\n",
       "      <td>8048.56000</td>\n",
       "      <td>9.34610</td>\n",
       "      <td>0.02000</td>\n",
       "      <td>334</td>\n",
       "      <td>2223</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>14.73000</td>\n",
       "      <td>8.80710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>41.99820</td>\n",
       "      <td>0.84080</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>445.00000</td>\n",
       "      <td>549.90000</td>\n",
       "      <td>1353.22000</td>\n",
       "      <td>1125.78000</td>\n",
       "      <td>3.91000</td>\n",
       "      <td>...</td>\n",
       "      <td>130.42000</td>\n",
       "      <td>2387.66000</td>\n",
       "      <td>8072.30000</td>\n",
       "      <td>9.37740</td>\n",
       "      <td>0.02000</td>\n",
       "      <td>330</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>10.41000</td>\n",
       "      <td>6.26650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>24.99880</td>\n",
       "      <td>0.62180</td>\n",
       "      <td>60.00000</td>\n",
       "      <td>462.54000</td>\n",
       "      <td>537.31000</td>\n",
       "      <td>1256.76000</td>\n",
       "      <td>1047.45000</td>\n",
       "      <td>7.05000</td>\n",
       "      <td>...</td>\n",
       "      <td>164.22000</td>\n",
       "      <td>2028.03000</td>\n",
       "      <td>7864.87000</td>\n",
       "      <td>10.89410</td>\n",
       "      <td>0.02000</td>\n",
       "      <td>309</td>\n",
       "      <td>1915</td>\n",
       "      <td>84.93000</td>\n",
       "      <td>14.08000</td>\n",
       "      <td>8.67230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>42.00770</td>\n",
       "      <td>0.84160</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>445.00000</td>\n",
       "      <td>549.51000</td>\n",
       "      <td>1354.03000</td>\n",
       "      <td>1126.38000</td>\n",
       "      <td>3.91000</td>\n",
       "      <td>...</td>\n",
       "      <td>130.72000</td>\n",
       "      <td>2387.61000</td>\n",
       "      <td>8068.66000</td>\n",
       "      <td>9.35280</td>\n",
       "      <td>0.02000</td>\n",
       "      <td>329</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>10.59000</td>\n",
       "      <td>6.47010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>25.00050</td>\n",
       "      <td>0.62030</td>\n",
       "      <td>60.00000</td>\n",
       "      <td>462.54000</td>\n",
       "      <td>537.07000</td>\n",
       "      <td>1257.71000</td>\n",
       "      <td>1047.93000</td>\n",
       "      <td>7.05000</td>\n",
       "      <td>...</td>\n",
       "      <td>164.31000</td>\n",
       "      <td>2028.00000</td>\n",
       "      <td>7861.23000</td>\n",
       "      <td>10.89630</td>\n",
       "      <td>0.02000</td>\n",
       "      <td>309</td>\n",
       "      <td>1915</td>\n",
       "      <td>84.93000</td>\n",
       "      <td>14.13000</td>\n",
       "      <td>8.52860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   engine_id  cycle  setting1  setting2  setting3        s1        s2  \\\n",
       "0          1      1  34.99830   0.84000 100.00000 449.44000 555.32000   \n",
       "1          1      2  41.99820   0.84080 100.00000 445.00000 549.90000   \n",
       "2          1      3  24.99880   0.62180  60.00000 462.54000 537.31000   \n",
       "3          1      4  42.00770   0.84160 100.00000 445.00000 549.51000   \n",
       "4          1      5  25.00050   0.62030  60.00000 462.54000 537.07000   \n",
       "\n",
       "          s3         s4      s5  ...       s12        s13        s14      s15  \\\n",
       "0 1358.61000 1137.23000 5.48000  ... 183.06000 2387.72000 8048.56000  9.34610   \n",
       "1 1353.22000 1125.78000 3.91000  ... 130.42000 2387.66000 8072.30000  9.37740   \n",
       "2 1256.76000 1047.45000 7.05000  ... 164.22000 2028.03000 7864.87000 10.89410   \n",
       "3 1354.03000 1126.38000 3.91000  ... 130.72000 2387.61000 8068.66000  9.35280   \n",
       "4 1257.71000 1047.93000 7.05000  ... 164.31000 2028.00000 7861.23000 10.89630   \n",
       "\n",
       "      s16  s17   s18       s19      s20     s21  \n",
       "0 0.02000  334  2223 100.00000 14.73000 8.80710  \n",
       "1 0.02000  330  2212 100.00000 10.41000 6.26650  \n",
       "2 0.02000  309  1915  84.93000 14.08000 8.67230  \n",
       "3 0.02000  329  2212 100.00000 10.59000 6.47010  \n",
       "4 0.02000  309  1915  84.93000 14.13000 8.52860  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_FD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtf_ids_train = train_FD['engine_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engine_id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s12</th>\n",
       "      <th>s13</th>\n",
       "      <th>s14</th>\n",
       "      <th>s15</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.99830</td>\n",
       "      <td>0.84000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>449.44000</td>\n",
       "      <td>555.32000</td>\n",
       "      <td>1358.61000</td>\n",
       "      <td>1137.23000</td>\n",
       "      <td>5.48000</td>\n",
       "      <td>...</td>\n",
       "      <td>183.06000</td>\n",
       "      <td>2387.72000</td>\n",
       "      <td>8048.56000</td>\n",
       "      <td>9.34610</td>\n",
       "      <td>0.02000</td>\n",
       "      <td>334</td>\n",
       "      <td>2223</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>14.73000</td>\n",
       "      <td>8.80710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>41.99820</td>\n",
       "      <td>0.84080</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>445.00000</td>\n",
       "      <td>549.90000</td>\n",
       "      <td>1353.22000</td>\n",
       "      <td>1125.78000</td>\n",
       "      <td>3.91000</td>\n",
       "      <td>...</td>\n",
       "      <td>130.42000</td>\n",
       "      <td>2387.66000</td>\n",
       "      <td>8072.30000</td>\n",
       "      <td>9.37740</td>\n",
       "      <td>0.02000</td>\n",
       "      <td>330</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>10.41000</td>\n",
       "      <td>6.26650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>24.99880</td>\n",
       "      <td>0.62180</td>\n",
       "      <td>60.00000</td>\n",
       "      <td>462.54000</td>\n",
       "      <td>537.31000</td>\n",
       "      <td>1256.76000</td>\n",
       "      <td>1047.45000</td>\n",
       "      <td>7.05000</td>\n",
       "      <td>...</td>\n",
       "      <td>164.22000</td>\n",
       "      <td>2028.03000</td>\n",
       "      <td>7864.87000</td>\n",
       "      <td>10.89410</td>\n",
       "      <td>0.02000</td>\n",
       "      <td>309</td>\n",
       "      <td>1915</td>\n",
       "      <td>84.93000</td>\n",
       "      <td>14.08000</td>\n",
       "      <td>8.67230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>42.00770</td>\n",
       "      <td>0.84160</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>445.00000</td>\n",
       "      <td>549.51000</td>\n",
       "      <td>1354.03000</td>\n",
       "      <td>1126.38000</td>\n",
       "      <td>3.91000</td>\n",
       "      <td>...</td>\n",
       "      <td>130.72000</td>\n",
       "      <td>2387.61000</td>\n",
       "      <td>8068.66000</td>\n",
       "      <td>9.35280</td>\n",
       "      <td>0.02000</td>\n",
       "      <td>329</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>10.59000</td>\n",
       "      <td>6.47010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>25.00050</td>\n",
       "      <td>0.62030</td>\n",
       "      <td>60.00000</td>\n",
       "      <td>462.54000</td>\n",
       "      <td>537.07000</td>\n",
       "      <td>1257.71000</td>\n",
       "      <td>1047.93000</td>\n",
       "      <td>7.05000</td>\n",
       "      <td>...</td>\n",
       "      <td>164.31000</td>\n",
       "      <td>2028.00000</td>\n",
       "      <td>7861.23000</td>\n",
       "      <td>10.89630</td>\n",
       "      <td>0.02000</td>\n",
       "      <td>309</td>\n",
       "      <td>1915</td>\n",
       "      <td>84.93000</td>\n",
       "      <td>14.13000</td>\n",
       "      <td>8.52860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>6</td>\n",
       "      <td>171</td>\n",
       "      <td>42.00150</td>\n",
       "      <td>0.84000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>445.00000</td>\n",
       "      <td>550.43000</td>\n",
       "      <td>1367.06000</td>\n",
       "      <td>1138.03000</td>\n",
       "      <td>3.91000</td>\n",
       "      <td>...</td>\n",
       "      <td>129.97000</td>\n",
       "      <td>2387.51000</td>\n",
       "      <td>8068.06000</td>\n",
       "      <td>9.49350</td>\n",
       "      <td>0.02000</td>\n",
       "      <td>333</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>10.59000</td>\n",
       "      <td>6.23360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>6</td>\n",
       "      <td>172</td>\n",
       "      <td>42.00360</td>\n",
       "      <td>0.84000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>445.00000</td>\n",
       "      <td>550.63000</td>\n",
       "      <td>1357.60000</td>\n",
       "      <td>1144.69000</td>\n",
       "      <td>3.91000</td>\n",
       "      <td>...</td>\n",
       "      <td>130.28000</td>\n",
       "      <td>2387.58000</td>\n",
       "      <td>8068.91000</td>\n",
       "      <td>9.47490</td>\n",
       "      <td>0.02000</td>\n",
       "      <td>332</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>10.51000</td>\n",
       "      <td>6.21010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>6</td>\n",
       "      <td>173</td>\n",
       "      <td>35.00740</td>\n",
       "      <td>0.84180</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>449.44000</td>\n",
       "      <td>556.61000</td>\n",
       "      <td>1372.17000</td>\n",
       "      <td>1148.06000</td>\n",
       "      <td>5.48000</td>\n",
       "      <td>...</td>\n",
       "      <td>182.74000</td>\n",
       "      <td>2387.84000</td>\n",
       "      <td>8055.89000</td>\n",
       "      <td>9.38850</td>\n",
       "      <td>0.02000</td>\n",
       "      <td>336</td>\n",
       "      <td>2223</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>14.61000</td>\n",
       "      <td>8.87020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>6</td>\n",
       "      <td>174</td>\n",
       "      <td>42.00540</td>\n",
       "      <td>0.84090</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>445.00000</td>\n",
       "      <td>550.70000</td>\n",
       "      <td>1363.60000</td>\n",
       "      <td>1139.32000</td>\n",
       "      <td>3.91000</td>\n",
       "      <td>...</td>\n",
       "      <td>130.16000</td>\n",
       "      <td>2387.53000</td>\n",
       "      <td>8070.74000</td>\n",
       "      <td>9.48100</td>\n",
       "      <td>0.02000</td>\n",
       "      <td>333</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>10.41000</td>\n",
       "      <td>6.29440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>6</td>\n",
       "      <td>175</td>\n",
       "      <td>42.00120</td>\n",
       "      <td>0.84040</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>445.00000</td>\n",
       "      <td>550.82000</td>\n",
       "      <td>1366.97000</td>\n",
       "      <td>1145.99000</td>\n",
       "      <td>3.91000</td>\n",
       "      <td>...</td>\n",
       "      <td>130.42000</td>\n",
       "      <td>2387.53000</td>\n",
       "      <td>8065.96000</td>\n",
       "      <td>9.46410</td>\n",
       "      <td>0.02000</td>\n",
       "      <td>334</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>10.54000</td>\n",
       "      <td>6.23130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1188 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      engine_id  cycle  setting1  setting2  setting3        s1        s2  \\\n",
       "0             1      1  34.99830   0.84000 100.00000 449.44000 555.32000   \n",
       "1             1      2  41.99820   0.84080 100.00000 445.00000 549.90000   \n",
       "2             1      3  24.99880   0.62180  60.00000 462.54000 537.31000   \n",
       "3             1      4  42.00770   0.84160 100.00000 445.00000 549.51000   \n",
       "4             1      5  25.00050   0.62030  60.00000 462.54000 537.07000   \n",
       "...         ...    ...       ...       ...       ...       ...       ...   \n",
       "1183          6    171  42.00150   0.84000 100.00000 445.00000 550.43000   \n",
       "1184          6    172  42.00360   0.84000 100.00000 445.00000 550.63000   \n",
       "1185          6    173  35.00740   0.84180 100.00000 449.44000 556.61000   \n",
       "1186          6    174  42.00540   0.84090 100.00000 445.00000 550.70000   \n",
       "1187          6    175  42.00120   0.84040 100.00000 445.00000 550.82000   \n",
       "\n",
       "             s3         s4      s5  ...       s12        s13        s14  \\\n",
       "0    1358.61000 1137.23000 5.48000  ... 183.06000 2387.72000 8048.56000   \n",
       "1    1353.22000 1125.78000 3.91000  ... 130.42000 2387.66000 8072.30000   \n",
       "2    1256.76000 1047.45000 7.05000  ... 164.22000 2028.03000 7864.87000   \n",
       "3    1354.03000 1126.38000 3.91000  ... 130.72000 2387.61000 8068.66000   \n",
       "4    1257.71000 1047.93000 7.05000  ... 164.31000 2028.00000 7861.23000   \n",
       "...         ...        ...     ...  ...       ...        ...        ...   \n",
       "1183 1367.06000 1138.03000 3.91000  ... 129.97000 2387.51000 8068.06000   \n",
       "1184 1357.60000 1144.69000 3.91000  ... 130.28000 2387.58000 8068.91000   \n",
       "1185 1372.17000 1148.06000 5.48000  ... 182.74000 2387.84000 8055.89000   \n",
       "1186 1363.60000 1139.32000 3.91000  ... 130.16000 2387.53000 8070.74000   \n",
       "1187 1366.97000 1145.99000 3.91000  ... 130.42000 2387.53000 8065.96000   \n",
       "\n",
       "          s15     s16  s17   s18       s19      s20     s21  \n",
       "0     9.34610 0.02000  334  2223 100.00000 14.73000 8.80710  \n",
       "1     9.37740 0.02000  330  2212 100.00000 10.41000 6.26650  \n",
       "2    10.89410 0.02000  309  1915  84.93000 14.08000 8.67230  \n",
       "3     9.35280 0.02000  329  2212 100.00000 10.59000 6.47010  \n",
       "4    10.89630 0.02000  309  1915  84.93000 14.13000 8.52860  \n",
       "...       ...     ...  ...   ...       ...      ...     ...  \n",
       "1183  9.49350 0.02000  333  2212 100.00000 10.59000 6.23360  \n",
       "1184  9.47490 0.02000  332  2212 100.00000 10.51000 6.21010  \n",
       "1185  9.38850 0.02000  336  2223 100.00000 14.61000 8.87020  \n",
       "1186  9.48100 0.02000  333  2212 100.00000 10.41000 6.29440  \n",
       "1187  9.46410 0.02000  334  2212 100.00000 10.54000 6.23130  \n",
       "\n",
       "[1188 rows x 26 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_FD.loc[train_FD['engine_id'].isin(list(rtf_ids_train[:6]))]\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtf_ids_test = test_FD['engine_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_FD.loc[test_FD['engine_id'].isin(list(rtf_ids_test[:2]))]\n",
    "RUL_FD_shortended = RUL_FD[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0\n",
       "0  18\n",
       "1  79"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RUL_FD_shortended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = rul.RemainingUsefulLife(train_data, test_data, RUL_FD_shortended, rtf_id= \"engine_id\", data_id = Data_id + \" same length as kaggel_plant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Configuration!\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " module_wrapper_2 (ModuleWra  (None, 5, 12, 1, 10)     5660      \n",
      " pper)                                                           \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 5, 12, 1, 10)     40        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " module_wrapper_3 (ModuleWra  (None, 8, 1, 20)         18160     \n",
      " pper)                                                           \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 8, 1, 20)         80        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 160)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 150)               24150     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 151       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,241\n",
      "Trainable params: 48,181\n",
      "Non-trainable params: 60\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "67/67 [==============================] - 22s 43ms/step - loss: 3946.0569 - val_loss: 563.4509 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 1071.9830 - val_loss: 494.5985 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 759.2385 - val_loss: 461.2844 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 623.6978 - val_loss: 407.9199 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "67/67 [==============================] - 2s 26ms/step - loss: 662.1969 - val_loss: 450.9258 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 609.6808 - val_loss: 281.6755 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "67/67 [==============================] - 2s 26ms/step - loss: 640.2780 - val_loss: 247.8864 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "67/67 [==============================] - 2s 26ms/step - loss: 555.1792 - val_loss: 873.8146 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "67/67 [==============================] - 2s 26ms/step - loss: 523.0063 - val_loss: 119.7404 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "67/67 [==============================] - 2s 26ms/step - loss: 504.7902 - val_loss: 427.0347 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "67/67 [==============================] - 2s 26ms/step - loss: 466.5033 - val_loss: 478.2139 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 469.3659 - val_loss: 275.7666 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 418.0045 - val_loss: 69.4029 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "67/67 [==============================] - 2s 26ms/step - loss: 443.6270 - val_loss: 1472.9047 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "67/67 [==============================] - 2s 26ms/step - loss: 454.9237 - val_loss: 2724.5576 - lr: 0.0010\n",
      "Epoch 16/30\n",
      "67/67 [==============================] - 2s 26ms/step - loss: 383.8844 - val_loss: 1838.9119 - lr: 0.0010\n",
      "Epoch 17/30\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 383.9605 - val_loss: 1093.2839 - lr: 0.0010\n",
      "Epoch 18/30\n",
      "67/67 [==============================] - ETA: 0s - loss: 362.6309\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "67/67 [==============================] - 2s 26ms/step - loss: 362.6309 - val_loss: 729.0835 - lr: 0.0010\n",
      "Epoch 19/30\n",
      "67/67 [==============================] - 2s 26ms/step - loss: 337.1058 - val_loss: 308.1820 - lr: 3.0000e-04\n",
      "Epoch 20/30\n",
      "67/67 [==============================] - 2s 26ms/step - loss: 326.3044 - val_loss: 73.9611 - lr: 3.0000e-04\n",
      "Epoch 21/30\n",
      "67/67 [==============================] - 2s 26ms/step - loss: 308.3155 - val_loss: 503.0025 - lr: 3.0000e-04\n",
      "Epoch 22/30\n",
      "67/67 [==============================] - 2s 26ms/step - loss: 296.2565 - val_loss: 260.2357 - lr: 3.0000e-04\n",
      "Epoch 23/30\n",
      "65/67 [============================>.] - ETA: 0s - loss: 305.0222\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "67/67 [==============================] - 2s 28ms/step - loss: 302.3366 - val_loss: 501.5574 - lr: 3.0000e-04\n",
      "Epoch 24/30\n",
      "67/67 [==============================] - 2s 26ms/step - loss: 271.6588 - val_loss: 1118.4611 - lr: 9.0000e-05\n",
      "Epoch 25/30\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 283.0550 - val_loss: 873.2690 - lr: 9.0000e-05\n",
      "Epoch 26/30\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 291.8980 - val_loss: 1071.4641 - lr: 9.0000e-05\n",
      "Epoch 27/30\n",
      "67/67 [==============================] - 2s 26ms/step - loss: 271.6067 - val_loss: 1263.8365 - lr: 9.0000e-05\n",
      "Epoch 28/30\n",
      "67/67 [==============================] - 2s 26ms/step - loss: 279.3931 - val_loss: 46.2467 - lr: 9.0000e-05\n",
      "Epoch 29/30\n",
      "67/67 [==============================] - 2s 27ms/step - loss: 258.7238 - val_loss: 379.2832 - lr: 9.0000e-05\n",
      "Epoch 30/30\n",
      "67/67 [==============================] - 2s 26ms/step - loss: 253.8804 - val_loss: 1914.1250 - lr: 9.0000e-05\n",
      "34/34 [==============================] - 1s 5ms/step\n",
      "The RMSE on Training dataset FD002 same length as kaggel_plant is 20.769290924072266.\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "The RMSE on test dataset FD002 same length as kaggel_plant is 21.092679977416992.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   y_batch_test  y_batch_pred_test\n",
       " 0      18.00000            1.56129\n",
       " 1      79.00000           54.10881,\n",
       "       y_batch_train  y_batch_train\n",
       " 0         120.00000       87.78246\n",
       " 1         120.00000       81.54220\n",
       " 2         120.00000       79.38106\n",
       " 3         120.00000       81.64371\n",
       " 4         120.00000       84.76417\n",
       " ...             ...            ...\n",
       " 1069        4.00000        7.70181\n",
       " 1070        3.00000        7.26994\n",
       " 1071        2.00000        7.56476\n",
       " 1072        1.00000        8.10680\n",
       " 1073        0.00000        9.45682\n",
       " \n",
       " [1074 rows x 2 columns])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.auto_rul()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the pipeline performs pretty well on CMPAS dataset despite being trained on a very small dataset (just 6 rtf_ids from CMAPSS).\n",
    "The reason for that could be that, CMPASS dataset is a relatively simple dataset so the model learns the patterns easily. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "de6709928cf2e8855f0ca4b57bbca8fbec23aa7e1023fb55e3401e919c59305b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
